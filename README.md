# Clothing Classifier

**Коган Анна Алексеевна**

Классификатор одежды на основе ResNet50.

## Постановка задачи

Определение типа одежды по изображению. Полезно для маркетплейсов и
онлайн-магазинов для автоматической разметки товаров.

## Формат данных

- **Вход**: изображение JPG/PNG, размер 224×224×3
- **Выход**: вектор вероятностей размерности 107 (количество классов, для
  которых в датасете хотя бы 10 экземпляра есть, это число можно настроить в
  параметре min_samples_per_class в файле dataset.py в модуле
  ClothingDataModule)

## Метрики

- Accuracy
- Top-5 Accuracy
- Macro F1-Score

У итоговой версии модели метрики на тестовой выборке такие:

- Accuracy: 82.7%
- Top-5 Accuracy: 98.0%
- Macro F1-Score: 47.2%

На всякий случай сохранила отдельно на диске веса модели, логи и графики (не
очень поняла про добавление папки plots в репозиторий, там же меняющаяся
информация). Ссылка: https://disk.yandex.ru/d/_JctayWQ6IbeOg

## Датасет

[Fashion Product Images Dataset](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-small)
— почти 45тыс изображений, 143 класса, из них 107 с хотя бы 10 экземплярами.
Взяла датасет с фотографиями низкого разрешения для высокой скорости загрузки
датасета и обучения.

---

## Setup

Проект создавался с помощью uv.

1. Установить uv: https://docs.astral.sh/uv/getting-started/installation/
2. В корне проекта выполнить:

```bash
uv sync
```

## Train

Для успешного запуска должен быть поднят mlflow server. Поэтому перед обучением
в отдельном окне надо выполнить команду:

```bash
uv run mlflow ui --port 8080
```

Далее для самого обучения надо из корня проекта выполнить команду:

```bash
uv run python clothing_classifier/train.py
```

При этом загружается датасет (внутри функции обучения вызывается функция
`download_data`, там либо из локального хранилища, настроенного с помощью dvc,
загружается файл, либо с kaggle. Для загрузки с kaggle надо добавить свой токен
в нужный файл. Инструкция: https://www.kaggle.com/docs/api)

Результаты сохраняются в:

- `checkpoints/` — веса модели
- `plots/` — графики (TensorBoard, CSV)
- `triton/export/onnx/` — ONNX модель
- MLflow UI: http://localhost:8080

### Параметры обучения

Конфигурация в `configs/`:

- `model/resnet50.yaml` — архитектура модели
- `training/default.yaml` — параметры обучения
- `optimizer/adamw.yaml` — оптимизатор

## Production preparation

Во время выполнения файла с обучением, после успешного обучения модель
конвертируется в `onnx`. Можно ее конвертировать с помощью функции `export_onnx`
из файла `utils.py`

Чтобы сконвертировать модель в формат TensorRT, надо выполнить команду:
`./scripts/convert2tensorrt.sh <путь до onnx модели от корня репозитория> <директория, в которую нужно поместить итоговую модель> <имя желаемой модели без расширения>`

## Infer

Можно запустить инференс на файле из датасета (или любом другом скачанном файле)
на модели в формате onnx: `uv run python infer.py --image <путь к изображению>`

Можно запустить инференс с помощью `triton`. Сначала надо запустить сервер:

````bash
cd triton
docker run --rm -p 8900:8000 -p 8901:8001 -p 8902:8002 \
    -v $(pwd)/model_repository:/models \
    --shm-size=1g \
    nvcr.io/nvidia/tritonserver:24.07-py3 \
    tritonserver --model-repository=/models --strict-model-config=false```

Потом можно поинференсить файл:
```bash
uv run python infer_triton.py --image <путь к изображению>
````
